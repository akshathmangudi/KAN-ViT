{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-16T15:02:18.570601Z",
     "iopub.status.busy": "2024-08-16T15:02:18.570213Z",
     "iopub.status.idle": "2024-08-16T15:02:23.112467Z",
     "shell.execute_reply": "2024-08-16T15:02:23.111506Z",
     "shell.execute_reply.started": "2024-08-16T15:02:18.570570Z"
    },
    "id": "ebuTLORXNuxR",
    "outputId": "594f4b68-9a57-4849-d3c6-f44bf13d7fb2",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7917b6f8f390>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "# Uncomment this line for MNIST training.\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm, trange\n",
    "from torch.optim import Adam\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T15:02:23.114456Z",
     "iopub.status.busy": "2024-08-16T15:02:23.114045Z",
     "iopub.status.idle": "2024-08-16T15:02:23.126603Z",
     "shell.execute_reply": "2024-08-16T15:02:23.125719Z",
     "shell.execute_reply.started": "2024-08-16T15:02:23.114430Z"
    },
    "id": "RPGqxBMNTcMU",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MSA(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This is the template implementation of the \"Multi-Scale Attention\" Layer.\n",
    "\n",
    "    The query, key and value mapping are matrix-multipled against each other in order to\n",
    "    find the attention, or, the relation of a word and its interaction with surrounding words.\n",
    "    \"\"\"\n",
    "    def __init__(self, d, n_heads=4):\n",
    "        super(MSA, self).__init__()\n",
    "        self.d = d\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        assert d % n_heads == 0  # Shouldn't divide dimension (d) into n_heads\n",
    "\n",
    "        d_head = int(d / n_heads)\n",
    "        self.q_mappings = torch.nn.ModuleList([torch.nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n",
    "        self.k_mappings = torch.nn.ModuleList([torch.nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n",
    "        self.v_mappings = torch.nn.ModuleList([torch.nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n",
    "        self.d_head = d_head\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, sequences):\n",
    "        result = []\n",
    "        for sequence in sequences:\n",
    "            seq_result = []\n",
    "            for head in range(self.n_heads):\n",
    "                q_mapping = self.q_mappings[head]\n",
    "                k_mapping = self.k_mappings[head]\n",
    "                v_mapping = self.v_mappings[head]\n",
    "\n",
    "                seq = sequence[:, head * self.d_head: (head + 1) * self.d_head]\n",
    "                q, k, v = q_mapping(seq), k_mapping(seq), v_mapping(seq)\n",
    "\n",
    "                attention = self.softmax(q @ k.T / (self.d_head ** 0.5))\n",
    "                seq_result.append(attention @ v)\n",
    "            result.append(torch.hstack(seq_result))\n",
    "        return torch.cat([torch.unsqueeze(r, dim=0) for r in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T15:02:23.128024Z",
     "iopub.status.busy": "2024-08-16T15:02:23.127691Z",
     "iopub.status.idle": "2024-08-16T15:02:49.908291Z",
     "shell.execute_reply": "2024-08-16T15:02:49.907343Z",
     "shell.execute_reply.started": "2024-08-16T15:02:23.127996Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting monai\n",
      "  Downloading monai-1.3.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch>=1.9 in /opt/conda/lib/python3.10/site-packages (from monai) (2.1.2)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from monai) (1.26.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (1.13.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (2024.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9->monai) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9->monai) (1.3.0)\n",
      "Downloading monai-1.3.2-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: monai\n",
      "Successfully installed monai-1.3.2\n",
      "Collecting einops\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: einops\n",
      "Successfully installed einops-0.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install monai\n",
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T15:02:49.911322Z",
     "iopub.status.busy": "2024-08-16T15:02:49.910996Z",
     "iopub.status.idle": "2024-08-16T15:02:49.950746Z",
     "shell.execute_reply": "2024-08-16T15:02:49.950007Z",
     "shell.execute_reply.started": "2024-08-16T15:02:49.911295Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from functools import partial\n",
    "from torch import nn, einsum\n",
    "from torch.autograd.function import Function\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "from torch.jit import fork, wait\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.nn import DataParallel\n",
    "# constants\n",
    "\n",
    "EPSILON = 1e-10\n",
    "\n",
    "# helper functions\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def default(val, d):\n",
    "    return val if exists(val) else d\n",
    "\n",
    "class FlashAttentionFunction(Function):\n",
    "    @staticmethod\n",
    "    @torch.no_grad()\n",
    "    def forward(ctx, q, k, v, mask, causal, q_bucket_size, k_bucket_size):\n",
    "        \"\"\" Algorithm 1 in the v2 paper \"\"\"\n",
    "\n",
    "        device = q.device\n",
    "        max_neg_value = -torch.finfo(q.dtype).max\n",
    "        qk_len_diff = max(k.shape[-2] - q.shape[-2], 0)\n",
    "\n",
    "        o = torch.zeros_like(q)\n",
    "        all_row_sums = torch.zeros((*q.shape[:-1], 1), device = device)\n",
    "        all_row_maxes = torch.full((*q.shape[:-1], 1), max_neg_value, device = device)\n",
    "\n",
    "        scale = (q.shape[-1] ** -0.5)\n",
    "\n",
    "        num_row_tiles = math.ceil(q.shape[-2] / q_bucket_size)\n",
    "        num_col_tiles = math.ceil(k.shape[-2] / k_bucket_size)\n",
    "\n",
    "        if exists(mask) and mask.ndim == 2:\n",
    "            mask = rearrange(mask, 'b n -> b 1 1 n')\n",
    "\n",
    "        if not exists(mask):\n",
    "            col_masks = (None,) * num_col_tiles\n",
    "            mask = (col_masks,) * num_row_tiles \n",
    "        else:\n",
    "            mask = ((mask,) * num_row_tiles) if mask.shape[-2] == 1 else mask.split(q_bucket_size, dim = -2)\n",
    "            mask = tuple(((row_mask,) * num_col_tiles) if row_mask.shape[-1] == 1 else row_mask.split(k_bucket_size, dim = -1) for row_mask in mask)\n",
    "\n",
    "        row_splits = zip(\n",
    "            q.split(q_bucket_size, dim = -2),\n",
    "            o.split(q_bucket_size, dim = -2),\n",
    "            mask,\n",
    "            all_row_sums.split(q_bucket_size, dim = -2),\n",
    "            all_row_maxes.split(q_bucket_size, dim = -2),\n",
    "        )\n",
    "\n",
    "        for ind, (qc, oc, row_mask, row_sums, row_maxes) in enumerate(row_splits):\n",
    "            q_start_index = ind * q_bucket_size - qk_len_diff\n",
    "\n",
    "            col_splits = zip(\n",
    "                k.split(k_bucket_size, dim = -2),\n",
    "                v.split(k_bucket_size, dim = -2),\n",
    "                row_mask\n",
    "            )\n",
    "\n",
    "            for k_ind, (kc, vc, col_mask) in enumerate(col_splits):\n",
    "                k_start_index = k_ind * k_bucket_size\n",
    "\n",
    "                attn_weights = einsum('... i d, ... j d -> ... i j', qc, kc) * scale\n",
    "\n",
    "                if exists(col_mask):\n",
    "                    attn_weights.masked_fill_(~col_mask, max_neg_value)\n",
    "\n",
    "                if causal and q_start_index < (k_start_index + k_bucket_size - 1):\n",
    "                    causal_mask = torch.ones((qc.shape[-2], kc.shape[-2]), dtype = torch.bool, device = device).triu(q_start_index - k_start_index + 1)\n",
    "                    attn_weights.masked_fill_(causal_mask, max_neg_value)\n",
    "\n",
    "                block_row_maxes = attn_weights.amax(dim = -1, keepdims = True)\n",
    "                new_row_maxes = torch.maximum(block_row_maxes, row_maxes)\n",
    "\n",
    "                exp_weights = torch.exp(attn_weights - new_row_maxes)\n",
    "\n",
    "                if exists(col_mask):\n",
    "                    exp_weights.masked_fill_(~col_mask, 0.)\n",
    "\n",
    "                block_row_sums = exp_weights.sum(dim = -1, keepdims = True).clamp(min = EPSILON)\n",
    "\n",
    "                exp_values = einsum('... i j, ... j d -> ... i d', exp_weights, vc)\n",
    "\n",
    "                exp_row_max_diff = torch.exp(row_maxes - new_row_maxes)\n",
    "\n",
    "                new_row_sums = exp_row_max_diff * row_sums + block_row_sums\n",
    "\n",
    "                oc.mul_(exp_row_max_diff).add_(exp_values)\n",
    "\n",
    "                row_maxes.copy_(new_row_maxes)\n",
    "                row_sums.copy_(new_row_sums)\n",
    "\n",
    "            oc.div_(row_sums)\n",
    "\n",
    "        lse = all_row_sums.log() + all_row_maxes\n",
    "\n",
    "        ctx.args = (causal, scale, mask, q_bucket_size, k_bucket_size)\n",
    "        ctx.save_for_backward(q, k, v, o, lse)\n",
    "\n",
    "        return o\n",
    "\n",
    "    @staticmethod\n",
    "    @torch.no_grad()\n",
    "    def backward(ctx, do):\n",
    "        \"\"\" Algorithm 2 in the v2 paper \"\"\"\n",
    "\n",
    "        causal, scale, mask, q_bucket_size, k_bucket_size = ctx.args\n",
    "        q, k, v, o, lse = ctx.saved_tensors\n",
    "\n",
    "        device = q.device\n",
    "\n",
    "        max_neg_value = -torch.finfo(q.dtype).max\n",
    "        qk_len_diff = max(k.shape[-2] - q.shape[-2], 0)\n",
    "\n",
    "        dq = torch.zeros_like(q)\n",
    "        dk = torch.zeros_like(k)\n",
    "        dv = torch.zeros_like(v)\n",
    "\n",
    "        row_splits = zip(\n",
    "            q.split(q_bucket_size, dim = -2),\n",
    "            o.split(q_bucket_size, dim = -2),\n",
    "            do.split(q_bucket_size, dim = -2),\n",
    "            mask,\n",
    "            lse.split(q_bucket_size, dim = -2),\n",
    "            dq.split(q_bucket_size, dim = -2)\n",
    "        )\n",
    "\n",
    "        for ind, (qc, oc, doc, row_mask, lsec, dqc) in enumerate(row_splits):\n",
    "            q_start_index = ind * q_bucket_size - qk_len_diff\n",
    "\n",
    "            col_splits = zip(\n",
    "                k.split(k_bucket_size, dim = -2),\n",
    "                v.split(k_bucket_size, dim = -2),\n",
    "                dk.split(k_bucket_size, dim = -2),\n",
    "                dv.split(k_bucket_size, dim = -2),\n",
    "                row_mask\n",
    "            )\n",
    "\n",
    "            for k_ind, (kc, vc, dkc, dvc, col_mask) in enumerate(col_splits):\n",
    "                k_start_index = k_ind * k_bucket_size\n",
    "\n",
    "                attn_weights = einsum('... i d, ... j d -> ... i j', qc, kc) * scale\n",
    "\n",
    "                if causal and q_start_index < (k_start_index + k_bucket_size - 1):\n",
    "                    causal_mask = torch.ones((qc.shape[-2], kc.shape[-2]), dtype = torch.bool, device = device).triu(q_start_index - k_start_index + 1)\n",
    "                    attn_weights.masked_fill_(causal_mask, max_neg_value)\n",
    "\n",
    "                p = torch.exp(attn_weights - lsec)\n",
    "\n",
    "                if exists(col_mask):\n",
    "                    p.masked_fill_(~col_mask, 0.)\n",
    "\n",
    "                dv_chunk = einsum('... i j, ... i d -> ... j d', p, doc)\n",
    "                dp = einsum('... i d, ... j d -> ... i j', doc, vc)\n",
    "\n",
    "                D = (doc * oc).sum(dim = -1, keepdims = True)\n",
    "                ds = p * scale * (dp - D)\n",
    "\n",
    "                dq_chunk = einsum('... i j, ... j d -> ... i d', ds, kc)\n",
    "                dk_chunk = einsum('... i j, ... i d -> ... j d', ds, qc)\n",
    "\n",
    "                dqc.add_(dq_chunk)\n",
    "                dkc.add_(dk_chunk)\n",
    "                dvc.add_(dv_chunk)\n",
    "\n",
    "        return dq, dk, dv, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T15:02:49.952305Z",
     "iopub.status.busy": "2024-08-16T15:02:49.951951Z",
     "iopub.status.idle": "2024-08-16T15:02:49.966325Z",
     "shell.execute_reply": "2024-08-16T15:02:49.965399Z",
     "shell.execute_reply.started": "2024-08-16T15:02:49.952256Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FlashAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        dim,\n",
    "        heads = 8,\n",
    "        dim_head = 64,\n",
    "        causal = False,\n",
    "        q_bucket_size = 512,\n",
    "        k_bucket_size = 1024,\n",
    "        parallel = False,\n",
    "        mixed_precision = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        self.causal = causal\n",
    "        self.parallel = parallel\n",
    "        self.mixed_precision = mixed_precision\n",
    "\n",
    "        inner_dim = heads * dim_head\n",
    "\n",
    "        self.to_q = nn.Linear(dim, inner_dim, bias = False)\n",
    "        self.to_kv = nn.Linear(dim, inner_dim * 2, bias = False)\n",
    "        self.to_out = nn.Linear(inner_dim, dim, bias = False)\n",
    "\n",
    "        # memory efficient attention related parameters\n",
    "        # can be overriden on forward\n",
    "        self.q_bucket_size = q_bucket_size\n",
    "        self.k_bucket_size = k_bucket_size\n",
    "\n",
    "        if self.parallel:\n",
    "            self.model = DataParallel(self)\n",
    "        if self.mixed_precision:\n",
    "            self.scaler = GradScaler()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        context = None,\n",
    "        mask = None,\n",
    "        q_bucket_size = None,\n",
    "        k_bucket_size = None,\n",
    "    ):\n",
    "        q_bucket_size = default(q_bucket_size, self.q_bucket_size)\n",
    "        k_bucket_size = default(k_bucket_size, self.k_bucket_size)\n",
    "\n",
    "        h = self.heads\n",
    "        context = default(context, x)\n",
    "\n",
    "        q = self.to_q(x)\n",
    "        k, v = self.to_kv(context).chunk(2, dim=-1)\n",
    "\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=h), (q, k, v))\n",
    "\n",
    "        if self.parallel:\n",
    "            # Split the input data into chunks and move each chunk to the correct GPU\n",
    "            num_gpus = torch.cuda.device_count()\n",
    "            x_chunks = x.split(x.size(0) // num_gpus)\n",
    "            x_chunks = [chunk.to(f'cuda:{i}') for i, chunk in enumerate(x_chunks)]\n",
    "            q = x_chunks\n",
    "\n",
    "        if self.mixed_precision:\n",
    "            # Use autocast to allow operations to run in lower precision\n",
    "            with autocast():\n",
    "                out = FlashAttentionFunction.apply(q, k, v, mask, self.causal, q_bucket_size, k_bucket_size)\n",
    "        else:\n",
    "            out = FlashAttentionFunction.apply(q, k, v, mask, self.causal, q_bucket_size, k_bucket_size)\n",
    "\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T15:02:49.968787Z",
     "iopub.status.busy": "2024-08-16T15:02:49.967566Z",
     "iopub.status.idle": "2024-08-16T15:02:49.987444Z",
     "shell.execute_reply": "2024-08-16T15:02:49.986725Z",
     "shell.execute_reply.started": "2024-08-16T15:02:49.968757Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FlashViT(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    The workflow will be as follows.\n",
    "        1. Find the linear mapping of the input\n",
    "        2. Embed them using the function that we have written\n",
    "        3. Use 'n' MSA blocks and add a linear and a softmax layer at the end\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, chw, n_patches=16, n_blocks=2, d_hidden=8, n_heads=4, out_d=10):\n",
    "        super(FlashViT, self).__init__()\n",
    "\n",
    "        self.chw = chw\n",
    "        self.n_patches = n_patches\n",
    "        self.n_blocks = n_blocks\n",
    "        self.n_heads = n_heads\n",
    "        self.d_hidden = d_hidden\n",
    "\n",
    "        # Input and patch sizes\n",
    "        assert chw[1] % n_patches == 0\n",
    "        assert chw[2] % n_patches == 0\n",
    "        self.patch_size = (chw[1] / n_patches, chw[2] / n_patches)\n",
    "\n",
    "        # Linear mapping\n",
    "        self.input_d = int(chw[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = torch.nn.Linear(self.input_d, self.d_hidden)\n",
    "\n",
    "        # Classification token\n",
    "        self.v_class = torch.nn.Parameter(torch.rand(1, self.d_hidden))\n",
    "\n",
    "        # Positional embedding\n",
    "        self.register_buffer('pos_embeddings', self.positional_embeddings(n_patches ** 2 + 1, d_hidden),\n",
    "                             persistent=False)\n",
    "\n",
    "        # Encoder blocks\n",
    "        self.blocks = torch.nn.ModuleList([FlashAttention(dim = d_hidden, heads = n_heads) for _ in range(n_blocks)])\n",
    "\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.d_hidden, out_d),\n",
    "            torch.nn.Softmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "    def patchify(self, images, n_patches):\n",
    "        \"\"\"\n",
    "        In order to \"sequentially\" pass in the images, we can break down the main image into multiple sub-images\n",
    "        and map them to a vector. This is exactly what this function does.\n",
    "\n",
    "        Arguments:\n",
    "        images: The image passed into this function\n",
    "        n_patches: The number of patches to split the image into.\n",
    "\n",
    "        Returns our patches aka the sub-images.\n",
    "        \"\"\"\n",
    "        n, c, h, w = images.shape\n",
    "\n",
    "        assert h == w, \"Only for square images\"\n",
    "\n",
    "        patches = torch.zeros(n, n_patches ** 2, h * w * c // n_patches ** 2)\n",
    "        patch_size = h // n_patches\n",
    "\n",
    "        for idx, image in enumerate(images):\n",
    "            for i in range(n_patches):\n",
    "                for j in range(n_patches):\n",
    "                    patch = image[:, i * patch_size: (i + 1) * patch_size, j * patch_size: (j + 1) * patch_size]\n",
    "                    patches[idx, i * n_patches + j] = patch.flatten()\n",
    "        return patches\n",
    "    \n",
    "    def positional_embeddings(self, sequence_length, d):\n",
    "        \"\"\"\n",
    "        In order for the model to know where to place each image, one can use positional embeddings where high freq values\n",
    "        are classified into the first few dimensions while low frequency values are added on to the latter dimensions. This\n",
    "        function performs exactly that. It has two parameters.\n",
    "\n",
    "        Arguments:\n",
    "        sequence_length: The number of tokens for the dataset.\n",
    "        d: The dimensionality for each token.\n",
    "\n",
    "        Returns a matrix where each (i,j) is added as token i in dimension j.\n",
    "        \"\"\"\n",
    "        result = torch.ones(sequence_length, d)\n",
    "        for i in range(sequence_length):\n",
    "            for j in range(d):\n",
    "                result[i][j] = np.sin(i / (10000 ** (j / d))) if j % 2 == 0 else np.cos(i / (10000 ** (j / d)))\n",
    "        return result\n",
    "\n",
    "    def forward(self, images):\n",
    "        n, c, h, w = images.shape\n",
    "        patches = self.patchify(images, self.n_patches).to(self.pos_embeddings.device)\n",
    "\n",
    "        # rutorch.nning tokenization\n",
    "        tokens = self.linear_mapper(patches)\n",
    "        tokens = torch.cat((self.v_class.expand(n, 1, -1), tokens), dim=1)\n",
    "        out = tokens + self.pos_embeddings.repeat(n, 1, 1)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            out = block(out)\n",
    "\n",
    "        out = out[:, 0]\n",
    "        return self.mlp(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T15:02:49.988985Z",
     "iopub.status.busy": "2024-08-16T15:02:49.988604Z",
     "iopub.status.idle": "2024-08-16T15:02:50.231764Z",
     "shell.execute_reply": "2024-08-16T15:02:50.230999Z",
     "shell.execute_reply.started": "2024-08-16T15:02:49.988958Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "mnist_model = FlashViT((1, 28, 28), n_patches=7, n_blocks=2, d_hidden=8, n_heads=2, out_d=10).to(device)\n",
    "optimizer = Adam(mnist_model.parameters(), lr=2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import datetime\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, roc_auc_score\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, y_pred_proba):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    y_true_bin = torch.nn.functional.one_hot(\n",
    "        torch.tensor(y_true), num_classes=10).numpy()\n",
    "    roc_auc = roc_auc_score(y_true_bin, y_pred_proba,\n",
    "                            average='weighted', multi_class='ovr')\n",
    "\n",
    "    return accuracy, balanced_accuracy, f1, roc_auc\n",
    "\n",
    "def save_metrics(filename, epoch, phase, loss, accuracy, balanced_accuracy, f1, roc_auc):\n",
    "    os.makedirs('logs', exist_ok=True)\n",
    "    with open(f'logs/{filename}', 'a') as f:\n",
    "        f.write(f\"Epoch: {epoch}, Phase: {phase}\\n\")\n",
    "        f.write(f\"  Loss: {loss:.4f}\\n\")\n",
    "        f.write(f\"  Accuracy: {accuracy:.4f}\\n\")\n",
    "        f.write(f\"  Balanced Accuracy: {balanced_accuracy:.4f}\\n\")\n",
    "        f.write(f\"  F1 Score: {f1:.4f}\\n\")\n",
    "        f.write(f\"  ROC AUC: {roc_auc:.4f}\\n\\n\")\n",
    "\n",
    "def main(train_loader, test_loader, epochs: int):\n",
    "    print(\"Using device: \", device,\n",
    "          f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Create a unique filename and TensorBoard writer for this run\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    log_filename = f\"flashvit_{epochs}epochs_{timestamp}.txt\"\n",
    "    train_writer = SummaryWriter(log_dir=f\"runs/flashvit_{epochs}epochs_{timestamp}/train\")\n",
    "    test_writer = SummaryWriter(log_dir=f\"runs/flashvit_{epochs}epochs_{timestamp}/test\")\n",
    "\n",
    "\n",
    "    for epoch in trange(epochs, desc=\"train\"):\n",
    "        train_loss = 0.0\n",
    "        y_true_train, y_pred_train, y_pred_proba_train = [], [], []\n",
    "\n",
    "        mnist_model.train()\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1} in training\", leave=False):\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = mnist_model(x)\n",
    "            loss = criterion(y_hat, y)\n",
    "\n",
    "            train_loss += loss.detach().cpu().item() / len(train_loader)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            y_true_train.extend(y.cpu().numpy())\n",
    "            y_pred_train.extend(torch.argmax(y_hat, dim=1).cpu().numpy())\n",
    "            y_pred_proba_train.extend(torch.nn.functional.softmax(\n",
    "                y_hat, dim=1).detach().cpu().numpy())\n",
    "\n",
    "        # Calculate training metrics\n",
    "        accuracy, balanced_accuracy, f1, roc_auc = calculate_metrics(\n",
    "            y_true_train, y_pred_train, y_pred_proba_train)\n",
    "\n",
    "        # Log training metrics to TensorBoard\n",
    "        train_writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "        train_writer.add_scalar('Accuracy/train', accuracy, epoch)\n",
    "        train_writer.add_scalar('Balanced Accuracy/train', balanced_accuracy, epoch)\n",
    "        train_writer.add_scalar('F1 Score/train', f1, epoch)\n",
    "        train_writer.add_scalar('ROC AUC/train', roc_auc, epoch)\n",
    "        \n",
    "        print(f\"Epoch: {epoch+1}, Phase: Train\")\n",
    "        print(f\"  Loss: {train_loss:.4f}\")\n",
    "        print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"  Balanced Accuracy: {balanced_accuracy:.4f}\")\n",
    "        print(f\"  F1 Score: {f1:.4f}\")\n",
    "        print(f\"  ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "        # Save metrics for the last epoch\n",
    "        if epoch == epochs - 1:\n",
    "            save_metrics(log_filename, epoch + 1, \"Train\",\n",
    "                         train_loss, accuracy, balanced_accuracy, f1, roc_auc)\n",
    "\n",
    "    # Testing\n",
    "    mnist_model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        y_true_test, y_pred_test, y_pred_proba_test = [], [], []\n",
    "\n",
    "        for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = mnist_model(x)\n",
    "            loss = criterion(y_hat, y)\n",
    "            test_loss += loss.detach().cpu().item() / len(test_loader)\n",
    "\n",
    "            y_true_test.extend(y.cpu().numpy())\n",
    "            y_pred_test.extend(torch.argmax(y_hat, dim=1).cpu().numpy())\n",
    "            y_pred_proba_test.extend(\n",
    "                torch.nn.functional.softmax(y_hat, dim=1).cpu().numpy())\n",
    "\n",
    "        # Calculate test metrics\n",
    "        accuracy, balanced_accuracy, f1, roc_auc = calculate_metrics(\n",
    "            y_true_test, y_pred_test, y_pred_proba_test)\n",
    "\n",
    "        # Log test metrics to TensorBoard\n",
    "        test_writer.add_scalar('Loss/test', test_loss, epochs)\n",
    "        test_writer.add_scalar('Accuracy/test', accuracy, epochs)\n",
    "        test_writer.add_scalar('Balanced Accuracy/test', balanced_accuracy, epochs)\n",
    "        test_writer.add_scalar('F1 Score/test', f1, epochs)\n",
    "        test_writer.add_scalar('ROC AUC/test', roc_auc, epochs)\n",
    "        \n",
    "        print(f\"Epoch: {epochs}, Phase: Train\")\n",
    "        print(f\"  Loss: {test_loss:.4f}\")\n",
    "        print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"  Balanced Accuracy: {balanced_accuracy:.4f}\")\n",
    "        print(f\"  F1 Score: {f1:.4f}\")\n",
    "        print(f\"  ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "        # Save test metrics\n",
    "        save_metrics(log_filename, epochs, \"Test\", test_loss,\n",
    "                     accuracy, balanced_accuracy, f1, roc_auc)\n",
    "\n",
    "    # Close the TensorBoard writer\n",
    "    train_writer.close()\n",
    "    test_writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-16T15:02:50.246185Z",
     "iopub.status.busy": "2024-08-16T15:02:50.245864Z",
     "iopub.status.idle": "2024-08-16T15:14:58.759191Z",
     "shell.execute_reply": "2024-08-16T15:14:58.758273Z",
     "shell.execute_reply.started": "2024-08-16T15:02:50.246157Z"
    },
    "id": "NYa8_XejN69n",
    "outputId": "0901cf5d-588e-4ada-80e8-129a5cce6dc5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "train_mnist = MNIST(root='./mnist', train=True, download=True, transform=transform)\n",
    "test_mnist = MNIST(root='./mnist', train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_mnist, shuffle=True, batch_size=128)\n",
    "test_loader = DataLoader(test_mnist, shuffle=False, batch_size=128)\n",
    "main(train_loader=train_loader, test_loader=test_loader, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
