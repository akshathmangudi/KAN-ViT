{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport math\nfrom typing import *","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-01T14:58:47.382374Z","iopub.execute_input":"2024-09-01T14:58:47.382666Z","iopub.status.idle":"2024-09-01T14:58:50.618059Z","shell.execute_reply.started":"2024-09-01T14:58:47.382633Z","shell.execute_reply":"2024-09-01T14:58:50.616983Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def forward_step(i_n, grid_size, A, K, C):\n    ratio = A * grid_size**(-K) + C\n    i_n1 = ratio * i_n\n    return i_n1\n\nclass SineKANLayer(torch.nn.Module):\n    def __init__(self, input_dim, output_dim, device='cuda', grid_size=5, is_first=False, add_bias=True, norm_freq=True):\n        super(SineKANLayer,self).__init__()\n        self.grid_size = grid_size\n        self.device = device\n        self.is_first = is_first\n        self.add_bias = add_bias\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.A, self.K, self.C = 0.9724108095811765, 0.9884401790754128, 0.999449553483052\n        \n        self.grid_norm_factor = (torch.arange(grid_size) + 1)\n        self.grid_norm_factor = self.grid_norm_factor.reshape(1, 1, grid_size)\n            \n        if is_first:\n            self.amplitudes = torch.nn.Parameter(torch.empty(output_dim, input_dim, 1).normal_(0, .4) / output_dim  / self.grid_norm_factor)\n        else:\n            self.amplitudes = torch.nn.Parameter(torch.empty(output_dim, input_dim, 1).uniform_(-1, 1) / output_dim  / self.grid_norm_factor)\n\n        grid_phase = torch.arange(1, grid_size + 1).reshape(1, 1, 1, grid_size) / (grid_size + 1)\n        self.input_phase = torch.linspace(0, math.pi, input_dim).reshape(1, 1, input_dim, 1).to(device)\n        phase = grid_phase.to(device) + self.input_phase\n\n        if norm_freq:\n            self.freq = torch.nn.Parameter(torch.arange(1, grid_size + 1).float().reshape(1, 1, 1, grid_size) / (grid_size + 1)**(1 - is_first))\n        else:\n            self.freq = torch.nn.Parameter(torch.arange(1, grid_size + 1).float().reshape(1, 1, 1, grid_size))\n\n        for i in range(1, self.grid_size):\n            phase = forward_step(phase, i, self.A, self.K, self.C)\n        # self.phase = torch.nn.Parameter(phase)\n        self.register_buffer('phase', phase)\n        \n        if self.add_bias:\n            self.bias  = torch.nn.Parameter(torch.ones(1, output_dim) / output_dim)\n\n    def forward(self, x):\n        x_shape = x.shape\n        output_shape = x_shape[0:-1] + (self.output_dim,)\n        x = torch.reshape(x, (-1, self.input_dim))\n        x_reshaped = torch.reshape(x, (x.shape[0], 1, x.shape[1], 1))\n        s = torch.sin(x_reshaped * self.freq + self.phase)\n        y = torch.einsum('ijkl,jkl->ij', s, self.amplitudes)\n        if self.add_bias:\n            y += self.bias\n        y = torch.reshape(y, output_shape)\n        return y","metadata":{"execution":{"iopub.status.busy":"2024-09-01T14:58:50.619925Z","iopub.execute_input":"2024-09-01T14:58:50.620452Z","iopub.status.idle":"2024-09-01T14:58:50.638004Z","shell.execute_reply.started":"2024-09-01T14:58:50.620407Z","shell.execute_reply":"2024-09-01T14:58:50.636916Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class MSA(torch.nn.Module):\n    \"\"\"\n        Initializes the Multi-Head Self-Attention (MSA) module with the given dimensions.\n\n        Args:\n            d (int): The total dimension of the input.\n            n_heads (int): The number of attention heads.\n\n        Returns:\n            None\n    \"\"\"\n    def __init__(self, d, n_heads):\n        super(NaiveFourierMSA, self).__init__()\n        self.d = d\n        self.n_heads = n_heads\n\n        assert d % n_heads == 0\n        d_head = int(d / n_heads)\n\n        self.q_mappings = torch.nn.ModuleList([SineKANLayer(d_head, d_head, grid_size=4) for _ in range(self.n_heads)])\n        self.k_mappings = torch.nn.ModuleList([SineKANLayer(d_head, d_head, grid_size=4) for _ in range(self.n_heads)])\n        self.v_mappings = torch.nn.ModuleList([SineKANLayer(d_head, d_head, grid_size=4) for _ in range(self.n_heads)])\n        self.d_head = d_head\n        self.softmax = torch.nn.Softmax(dim=-1)\n\n    def forward(self, sequence):\n        result = []\n        for sequence in sequence:\n            seq_res = []\n            for head in range(self.n_heads):\n                q_map = self.q_mappings[head]\n                k_map = self.k_mappings[head]\n                v_map = self.v_mappings[head]\n\n                seq = sequence[:, head*self.d_head: (head+1)*self.d_head]\n                q, k, v = q_map(seq), k_map(seq), v_map(seq)\n\n                attention = self.softmax(q @ k.T / (self.d_head ** 0.5))\n                seq_res.append(attention @ v)\n            result.append(torch.hstack(seq_res))\n        return torch.cat([torch.unsqueeze(r, dim=0) for r in result])","metadata":{"execution":{"iopub.status.busy":"2024-09-01T15:02:43.013042Z","iopub.execute_input":"2024-09-01T15:02:43.013439Z","iopub.status.idle":"2024-09-01T15:02:43.025325Z","shell.execute_reply.started":"2024-09-01T15:02:43.013402Z","shell.execute_reply":"2024-09-01T15:02:43.024224Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import numpy\n\nclass SineKAN_ViT(torch.nn.Module): \n    \"\"\"\n        Initializes a Vision Transformer (ViT) module.\n\n        Args:\n            chw (list/tuple of 3 ints): The input image shape.\n            n_patches (int, optional): The number of patches to split the image into. Defaults to 10.\n            n_blocks (int, optional): The number of blocks in the transformer encoder. Defaults to 2.\n            d_hidden (int, optional): The number of hidden dimensions in the transformer encoder. Defaults to 8.\n            n_heads (int, optional): The number of attention heads in each block. Defaults to 2.\n            out_d (int, optional): The number of output dimensions. Defaults to 10.\n\n        Returns:\n            None\n    \"\"\"    \n    def __init__(self, chw, n_patches=10, n_blocks=2, d_hidden=8, n_heads=2, out_d=10): \n        super(SineKAN_ViT, self).__init__()\n        \n        self.chw = chw\n        self.n_patches = n_patches\n        self.n_blocks = n_blocks\n        self.n_heads = n_heads\n        self.d_hidden = d_hidden\n        \n        assert chw[1] % n_patches == 0 \n        assert chw[2] % n_patches == 0\n        \n        self.patch_size = (chw[1] / n_patches, chw[2] / n_patches)\n\n        # Linear mapping\n        self.input_d = int(chw[0] * self.patch_size[0] * self.patch_size[1])\n        self.linear_mapper = SineKANLayer(self.input_d, self.d_hidden, grid_size=28)\n\n        # Classification token\n        self.v_class = torch.nn.Parameter(torch.rand(1, self.d_hidden))\n\n        # Positional embedding\n        self.register_buffer('pos_embeddings', self.positional_embeddings(n_patches ** 2 + 1, d_hidden),\n                             persistent=False)\n\n        # Encoder blocks\n        self.blocks = torch.nn.ModuleList([NaiveFourierMSA(d_hidden, n_heads) for _ in range(n_blocks)])\n\n        self.mlp = torch.nn.Sequential(\n            SineKANLayer(self.d_hidden, out_d, grid_size=4),\n            torch.nn.Softmax(dim=-1)\n        )\n        \n    def patchify(self, images, n_patches):\n        \"\"\"\n        The purpose of this function is to break down the main image into multiple sub-images and map them.\n\n        Args:\n            images (_type_): The image passeed into this function.\n            n_patches (_type_): The number of sub-images that will be created.\n        \"\"\"\n\n        n, c, h, w = images.shape\n        assert h == w, \"Only for square images\"\n\n        patches = torch.zeros(n, n_patches**2, h * w * c // n_patches ** 2) # The equation to calculate the patches\n        patch_size = h // n_patches\n\n        for idx, image in enumerate(images):\n            for i in range(n_patches):\n                for j in range(n_patches):\n                    patch = image[:, i * patch_size: (i + 1) * patch_size, j * patch_size: (j + 1) * patch_size]\n                    patches[idx, i * n_patches + j] = patch.flatten()\n        return patches\n\n    def positional_embeddings(self, seq_length, d):\n        \"\"\"\n        the purpose of this function is to find high and low interaction of a word with surrounding words.\n        We can do so by the following equation below:\n\n        Args:\n            seq_length (int): The length of the sequence/sentence\n            d (int): The dimension of the embedding\n        \"\"\"\n\n        result = torch.ones(seq_length, d)\n        for i in range(seq_length):\n            for j in range(d):\n                result[i][j] = numpy.sin(i / 10000 ** (j / d)) if j % 2 == 0 else numpy.cos(i / 10000 ** (j/ d))\n        return result\n\n    def forward(self, images):\n        n, c, h, w = images.shape\n        patches = self.patchify(images, self.n_patches).to(self.pos_embeddings.device)\n\n        # running tokenization\n        tokens = self.linear_mapper(patches)\n        tokens = torch.cat((self.v_class.expand(n, 1, -1), tokens), dim=1)\n        out = tokens + self.pos_embeddings.repeat(n, 1, 1)\n\n        for block in self.blocks:\n            out = block(out)\n\n        out = out[:, 0]\n        return self.mlp(out)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T15:03:35.340735Z","iopub.execute_input":"2024-09-01T15:03:35.341548Z","iopub.status.idle":"2024-09-01T15:03:35.363505Z","shell.execute_reply.started":"2024-09-01T15:03:35.341505Z","shell.execute_reply":"2024-09-01T15:03:35.362386Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from torch.optim import Adam\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmnist_model = SineKAN_ViT((1, 28, 28), n_patches=7, n_blocks=2, d_hidden=8, n_heads=2, out_d=10).to(device)\noptimizer = Adam(mnist_model.parameters(), lr=0.005)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T15:03:37.791351Z","iopub.execute_input":"2024-09-01T15:03:37.791720Z","iopub.status.idle":"2024-09-01T15:03:38.720585Z","shell.execute_reply.started":"2024-09-01T15:03:37.791687Z","shell.execute_reply":"2024-09-01T15:03:38.719701Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision.datasets import MNIST\nfrom tqdm import tqdm, trange\n\ndef main(train_loader, test_loader):\n    \"\"\"\n    This code contains the training and testing loop for training the vision transformers model. It requires two\n    parameters\n\n    :param train_loader: The dataloader for the training set for training the model.\n    :param test_loader: The dataloader for the testing set during evaluation phase.\n    \"\"\"\n    print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")\n\n    epochs = 10\n    criterion = torch.nn.CrossEntropyLoss()\n    for epoch in trange(epochs, desc=\"train\"):\n        train_loss = 0.0\n        for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1} in training\", leave=False):\n            x, y = batch\n            x, y = x.to(device), y.to(device)\n            y_hat = mnist_model(x)\n            loss = criterion(y_hat, y)\n\n            train_loss += loss.detach().cpu().item() / len(train_loader)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch + 1}/{epochs} loss: {train_loss:.2f}\")\n\n    with torch.no_grad():\n        correct, total = 0, 0\n        test_loss = 0.0\n        for batch in tqdm(test_loader, desc=\"Testing\"):\n            x, y = batch\n            x, y = x.to(device), y.to(device)\n            y_hat = mnist_model(x)\n            loss = criterion(y_hat, y)\n            test_loss += loss.detach().cpu().item() / len(test_loader)\n\n            correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n            total += len(x)\n\n        print(f\"Test loss: {test_loss:.2f}\")\n        print(f\"Test accuracy: {correct / total * 100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-09-01T15:03:46.502343Z","iopub.execute_input":"2024-09-01T15:03:46.503491Z","iopub.status.idle":"2024-09-01T15:03:46.956925Z","shell.execute_reply.started":"2024-09-01T15:03:46.503448Z","shell.execute_reply":"2024-09-01T15:03:46.955967Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"transform = transforms.ToTensor()\ntrain_mnist = MNIST(root='./mnist', train=True, download=True, transform=transform)\ntest_mnist = MNIST(root='./mnist', train=False, download=True, transform=transform)\ntrain_loader = DataLoader(train_mnist, shuffle=True, batch_size=128)\ntest_loader = DataLoader(test_mnist, shuffle=False, batch_size=128)\nmain(train_loader=train_loader, test_loader=test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T15:04:03.804210Z","iopub.execute_input":"2024-09-01T15:04:03.804624Z","iopub.status.idle":"2024-09-01T15:07:52.984703Z","shell.execute_reply.started":"2024-09-01T15:04:03.804586Z","shell.execute_reply":"2024-09-01T15:07:52.983310Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 15639815.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 457462.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1648877/1648877 [00:00<00:00, 4270711.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 3503223.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n\nUsing device:  cuda (Tesla T4)\n","output_type":"stream"},{"name":"stderr","text":"train:   0%|          | 0/10 [00:00<?, ?it/s]\nEpoch 1 in training:   0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\nEpoch 1 in training:   0%|          | 1/469 [00:01<14:33,  1.87s/it]\u001b[A\nEpoch 1 in training:   0%|          | 2/469 [00:03<12:28,  1.60s/it]\u001b[A\nEpoch 1 in training:   1%|          | 3/469 [00:04<11:49,  1.52s/it]\u001b[A\nEpoch 1 in training:   1%|          | 4/469 [00:06<11:31,  1.49s/it]\u001b[A\nEpoch 1 in training:   1%|          | 5/469 [00:07<11:27,  1.48s/it]\u001b[A\nEpoch 1 in training:   1%|▏         | 6/469 [00:09<11:17,  1.46s/it]\u001b[A\nEpoch 1 in training:   1%|▏         | 7/469 [00:10<11:13,  1.46s/it]\u001b[A\nEpoch 1 in training:   2%|▏         | 8/469 [00:11<11:06,  1.44s/it]\u001b[A\nEpoch 1 in training:   2%|▏         | 9/469 [00:13<11:01,  1.44s/it]\u001b[A\nEpoch 1 in training:   2%|▏         | 10/469 [00:14<10:58,  1.44s/it]\u001b[A\nEpoch 1 in training:   2%|▏         | 11/469 [00:16<10:59,  1.44s/it]\u001b[A\nEpoch 1 in training:   3%|▎         | 12/469 [00:17<11:03,  1.45s/it]\u001b[A\nEpoch 1 in training:   3%|▎         | 13/469 [00:19<10:58,  1.44s/it]\u001b[A\nEpoch 1 in training:   3%|▎         | 14/469 [00:20<10:56,  1.44s/it]\u001b[A\nEpoch 1 in training:   3%|▎         | 15/469 [00:22<11:06,  1.47s/it]\u001b[A\nEpoch 1 in training:   3%|▎         | 16/469 [00:23<11:01,  1.46s/it]\u001b[A\nEpoch 1 in training:   4%|▎         | 17/469 [00:24<10:56,  1.45s/it]\u001b[A\nEpoch 1 in training:   4%|▍         | 18/469 [00:26<10:59,  1.46s/it]\u001b[A\nEpoch 1 in training:   4%|▍         | 19/469 [00:27<10:57,  1.46s/it]\u001b[A\nEpoch 1 in training:   4%|▍         | 20/469 [00:29<10:51,  1.45s/it]\u001b[A\nEpoch 1 in training:   4%|▍         | 21/469 [00:30<10:48,  1.45s/it]\u001b[A\nEpoch 1 in training:   5%|▍         | 22/469 [00:32<10:44,  1.44s/it]\u001b[A\nEpoch 1 in training:   5%|▍         | 23/469 [00:33<10:43,  1.44s/it]\u001b[A\nEpoch 1 in training:   5%|▌         | 24/469 [00:35<10:56,  1.47s/it]\u001b[A\nEpoch 1 in training:   5%|▌         | 25/469 [00:36<10:59,  1.49s/it]\u001b[A\nEpoch 1 in training:   6%|▌         | 26/469 [00:38<10:55,  1.48s/it]\u001b[A\nEpoch 1 in training:   6%|▌         | 27/469 [00:39<10:48,  1.47s/it]\u001b[A\nEpoch 1 in training:   6%|▌         | 28/469 [00:41<10:44,  1.46s/it]\u001b[A\nEpoch 1 in training:   6%|▌         | 29/469 [00:42<10:38,  1.45s/it]\u001b[A\nEpoch 1 in training:   6%|▋         | 30/469 [00:43<10:35,  1.45s/it]\u001b[A\nEpoch 1 in training:   7%|▋         | 31/469 [00:45<10:32,  1.44s/it]\u001b[A\nEpoch 1 in training:   7%|▋         | 32/469 [00:46<10:33,  1.45s/it]\u001b[A\nEpoch 1 in training:   7%|▋         | 33/469 [00:48<10:31,  1.45s/it]\u001b[A\nEpoch 1 in training:   7%|▋         | 34/469 [00:49<10:32,  1.45s/it]\u001b[A\nEpoch 1 in training:   7%|▋         | 35/469 [00:51<10:28,  1.45s/it]\u001b[A\nEpoch 1 in training:   8%|▊         | 36/469 [00:52<10:38,  1.47s/it]\u001b[A\nEpoch 1 in training:   8%|▊         | 37/469 [00:54<10:35,  1.47s/it]\u001b[A\nEpoch 1 in training:   8%|▊         | 38/469 [00:55<10:31,  1.46s/it]\u001b[A\nEpoch 1 in training:   8%|▊         | 39/469 [00:57<10:33,  1.47s/it]\u001b[A\nEpoch 1 in training:   9%|▊         | 40/469 [00:58<10:28,  1.47s/it]\u001b[A\nEpoch 1 in training:   9%|▊         | 41/469 [00:59<10:21,  1.45s/it]\u001b[A\nEpoch 1 in training:   9%|▉         | 42/469 [01:01<10:19,  1.45s/it]\u001b[A\nEpoch 1 in training:   9%|▉         | 43/469 [01:02<10:15,  1.45s/it]\u001b[A\nEpoch 1 in training:   9%|▉         | 44/469 [01:04<10:13,  1.44s/it]\u001b[A\nEpoch 1 in training:  10%|▉         | 45/469 [01:05<10:11,  1.44s/it]\u001b[A\nEpoch 1 in training:  10%|▉         | 46/469 [01:07<10:12,  1.45s/it]\u001b[A\nEpoch 1 in training:  10%|█         | 47/469 [01:08<10:12,  1.45s/it]\u001b[A\nEpoch 1 in training:  10%|█         | 48/469 [01:10<10:08,  1.45s/it]\u001b[A\nEpoch 1 in training:  10%|█         | 49/469 [01:11<10:07,  1.45s/it]\u001b[A\nEpoch 1 in training:  11%|█         | 50/469 [01:12<10:02,  1.44s/it]\u001b[A\nEpoch 1 in training:  11%|█         | 51/469 [01:14<09:59,  1.43s/it]\u001b[A\nEpoch 1 in training:  11%|█         | 52/469 [01:15<10:14,  1.47s/it]\u001b[A\nEpoch 1 in training:  11%|█▏        | 53/469 [01:17<10:17,  1.48s/it]\u001b[A\nEpoch 1 in training:  12%|█▏        | 54/469 [01:18<10:11,  1.47s/it]\u001b[A\nEpoch 1 in training:  12%|█▏        | 55/469 [01:20<10:07,  1.47s/it]\u001b[A\nEpoch 1 in training:  12%|█▏        | 56/469 [01:21<10:05,  1.47s/it]\u001b[A\nEpoch 1 in training:  12%|█▏        | 57/469 [01:23<10:02,  1.46s/it]\u001b[A\nEpoch 1 in training:  12%|█▏        | 58/469 [01:24<10:06,  1.47s/it]\u001b[A\nEpoch 1 in training:  13%|█▎        | 59/469 [01:26<10:03,  1.47s/it]\u001b[A\nEpoch 1 in training:  13%|█▎        | 60/469 [01:27<10:09,  1.49s/it]\u001b[A\nEpoch 1 in training:  13%|█▎        | 61/469 [01:29<10:05,  1.48s/it]\u001b[A\nEpoch 1 in training:  13%|█▎        | 62/469 [01:30<09:58,  1.47s/it]\u001b[A\nEpoch 1 in training:  13%|█▎        | 63/469 [01:32<09:51,  1.46s/it]\u001b[A\nEpoch 1 in training:  14%|█▎        | 64/469 [01:33<09:48,  1.45s/it]\u001b[A\nEpoch 1 in training:  14%|█▍        | 65/469 [01:34<09:43,  1.45s/it]\u001b[A\nEpoch 1 in training:  14%|█▍        | 66/469 [01:36<09:50,  1.47s/it]\u001b[A\nEpoch 1 in training:  14%|█▍        | 67/469 [01:37<09:47,  1.46s/it]\u001b[A\nEpoch 1 in training:  14%|█▍        | 68/469 [01:39<09:44,  1.46s/it]\u001b[A\nEpoch 1 in training:  15%|█▍        | 69/469 [01:40<09:42,  1.46s/it]\u001b[A\nEpoch 1 in training:  15%|█▍        | 70/469 [01:42<09:39,  1.45s/it]\u001b[A\nEpoch 1 in training:  15%|█▌        | 71/469 [01:43<09:36,  1.45s/it]\u001b[A\nEpoch 1 in training:  15%|█▌        | 72/469 [01:45<09:34,  1.45s/it]\u001b[A\nEpoch 1 in training:  16%|█▌        | 73/469 [01:46<09:36,  1.45s/it]\u001b[A\nEpoch 1 in training:  16%|█▌        | 74/469 [01:48<09:33,  1.45s/it]\u001b[A\nEpoch 1 in training:  16%|█▌        | 75/469 [01:49<09:32,  1.45s/it]\u001b[A\nEpoch 1 in training:  16%|█▌        | 76/469 [01:50<09:30,  1.45s/it]\u001b[A\nEpoch 1 in training:  16%|█▋        | 77/469 [01:52<09:29,  1.45s/it]\u001b[A\nEpoch 1 in training:  17%|█▋        | 78/469 [01:53<09:28,  1.45s/it]\u001b[A\nEpoch 1 in training:  17%|█▋        | 79/469 [01:55<09:47,  1.51s/it]\u001b[A\nEpoch 1 in training:  17%|█▋        | 80/469 [01:57<09:54,  1.53s/it]\u001b[A\nEpoch 1 in training:  17%|█▋        | 81/469 [01:58<09:41,  1.50s/it]\u001b[A\nEpoch 1 in training:  17%|█▋        | 82/469 [01:59<09:32,  1.48s/it]\u001b[A\nEpoch 1 in training:  18%|█▊        | 83/469 [02:01<09:27,  1.47s/it]\u001b[A\nEpoch 1 in training:  18%|█▊        | 84/469 [02:02<09:22,  1.46s/it]\u001b[A\nEpoch 1 in training:  18%|█▊        | 85/469 [02:04<09:16,  1.45s/it]\u001b[A\nEpoch 1 in training:  18%|█▊        | 86/469 [02:05<09:13,  1.45s/it]\u001b[A\nEpoch 1 in training:  19%|█▊        | 87/469 [02:07<09:14,  1.45s/it]\u001b[A\nEpoch 1 in training:  19%|█▉        | 88/469 [02:08<09:10,  1.44s/it]\u001b[A\nEpoch 1 in training:  19%|█▉        | 89/469 [02:10<09:07,  1.44s/it]\u001b[A\nEpoch 1 in training:  19%|█▉        | 90/469 [02:11<09:04,  1.44s/it]\u001b[A\nEpoch 1 in training:  19%|█▉        | 91/469 [02:12<09:03,  1.44s/it]\u001b[A\nEpoch 1 in training:  20%|█▉        | 92/469 [02:14<09:00,  1.43s/it]\u001b[A\nEpoch 1 in training:  20%|█▉        | 93/469 [02:15<08:58,  1.43s/it]\u001b[A\nEpoch 1 in training:  20%|██        | 94/469 [02:17<09:00,  1.44s/it]\u001b[A\nEpoch 1 in training:  20%|██        | 95/469 [02:18<08:58,  1.44s/it]\u001b[A\nEpoch 1 in training:  20%|██        | 96/469 [02:20<08:57,  1.44s/it]\u001b[A\nEpoch 1 in training:  21%|██        | 97/469 [02:21<08:55,  1.44s/it]\u001b[A\nEpoch 1 in training:  21%|██        | 98/469 [02:23<08:55,  1.44s/it]\u001b[A\nEpoch 1 in training:  21%|██        | 99/469 [02:24<08:53,  1.44s/it]\u001b[A\nEpoch 1 in training:  21%|██▏       | 100/469 [02:25<08:53,  1.45s/it]\u001b[A\nEpoch 1 in training:  22%|██▏       | 101/469 [02:27<09:06,  1.49s/it]\u001b[A\nEpoch 1 in training:  22%|██▏       | 102/469 [02:28<09:01,  1.48s/it]\u001b[A\nEpoch 1 in training:  22%|██▏       | 103/469 [02:30<08:54,  1.46s/it]\u001b[A\nEpoch 1 in training:  22%|██▏       | 104/469 [02:31<08:51,  1.46s/it]\u001b[A\nEpoch 1 in training:  22%|██▏       | 105/469 [02:33<08:48,  1.45s/it]\u001b[A\nEpoch 1 in training:  23%|██▎       | 106/469 [02:34<08:46,  1.45s/it]\u001b[A\nEpoch 1 in training:  23%|██▎       | 107/469 [02:36<08:47,  1.46s/it]\u001b[A\nEpoch 1 in training:  23%|██▎       | 108/469 [02:37<08:47,  1.46s/it]\u001b[A\nEpoch 1 in training:  23%|██▎       | 109/469 [02:39<08:56,  1.49s/it]\u001b[A\nEpoch 1 in training:  23%|██▎       | 110/469 [02:40<08:49,  1.48s/it]\u001b[A\nEpoch 1 in training:  24%|██▎       | 111/469 [02:42<08:43,  1.46s/it]\u001b[A\nEpoch 1 in training:  24%|██▍       | 112/469 [02:43<08:39,  1.45s/it]\u001b[A\nEpoch 1 in training:  24%|██▍       | 113/469 [02:44<08:36,  1.45s/it]\u001b[A\nEpoch 1 in training:  24%|██▍       | 114/469 [02:46<08:36,  1.46s/it]\u001b[A\nEpoch 1 in training:  25%|██▍       | 115/469 [02:47<08:32,  1.45s/it]\u001b[A\nEpoch 1 in training:  25%|██▍       | 116/469 [02:49<08:34,  1.46s/it]\u001b[A\nEpoch 1 in training:  25%|██▍       | 117/469 [02:50<08:32,  1.45s/it]\u001b[A\nEpoch 1 in training:  25%|██▌       | 118/469 [02:52<08:28,  1.45s/it]\u001b[A\nEpoch 1 in training:  25%|██▌       | 119/469 [02:53<08:25,  1.44s/it]\u001b[A\nEpoch 1 in training:  26%|██▌       | 120/469 [02:55<08:22,  1.44s/it]\u001b[A\nEpoch 1 in training:  26%|██▌       | 121/469 [02:56<08:23,  1.45s/it]\u001b[A\nEpoch 1 in training:  26%|██▌       | 122/469 [02:57<08:23,  1.45s/it]\u001b[A\nEpoch 1 in training:  26%|██▌       | 123/469 [02:59<08:29,  1.47s/it]\u001b[A\nEpoch 1 in training:  26%|██▋       | 124/469 [03:00<08:25,  1.47s/it]\u001b[A\nEpoch 1 in training:  27%|██▋       | 125/469 [03:02<08:21,  1.46s/it]\u001b[A\nEpoch 1 in training:  27%|██▋       | 126/469 [03:03<08:17,  1.45s/it]\u001b[A\nEpoch 1 in training:  27%|██▋       | 127/469 [03:05<08:14,  1.45s/it]\u001b[A\nEpoch 1 in training:  27%|██▋       | 128/469 [03:06<08:15,  1.45s/it]\u001b[A\nEpoch 1 in training:  28%|██▊       | 129/469 [03:08<08:12,  1.45s/it]\u001b[A\nEpoch 1 in training:  28%|██▊       | 130/469 [03:09<08:10,  1.45s/it]\u001b[A\nEpoch 1 in training:  28%|██▊       | 131/469 [03:11<08:07,  1.44s/it]\u001b[A\nEpoch 1 in training:  28%|██▊       | 132/469 [03:12<08:05,  1.44s/it]\u001b[A\nEpoch 1 in training:  28%|██▊       | 133/469 [03:13<08:03,  1.44s/it]\u001b[A\nEpoch 1 in training:  29%|██▊       | 134/469 [03:15<08:13,  1.47s/it]\u001b[A\nEpoch 1 in training:  29%|██▉       | 135/469 [03:16<08:11,  1.47s/it]\u001b[A\nEpoch 1 in training:  29%|██▉       | 136/469 [03:18<08:06,  1.46s/it]\u001b[A\nEpoch 1 in training:  29%|██▉       | 137/469 [03:19<08:02,  1.45s/it]\u001b[A\nEpoch 1 in training:  29%|██▉       | 138/469 [03:21<07:59,  1.45s/it]\u001b[A\nEpoch 1 in training:  30%|██▉       | 139/469 [03:22<07:56,  1.44s/it]\u001b[A\nEpoch 1 in training:  30%|██▉       | 140/469 [03:24<07:53,  1.44s/it]\u001b[A\nEpoch 1 in training:  30%|███       | 141/469 [03:25<07:52,  1.44s/it]\u001b[A\nEpoch 1 in training:  30%|███       | 142/469 [03:27<07:56,  1.46s/it]\u001b[A\nEpoch 1 in training:  30%|███       | 143/469 [03:28<07:52,  1.45s/it]\u001b[A\nEpoch 1 in training:  31%|███       | 144/469 [03:29<07:53,  1.46s/it]\u001b[A\nEpoch 1 in training:  31%|███       | 145/469 [03:31<07:56,  1.47s/it]\u001b[A\nEpoch 1 in training:  31%|███       | 146/469 [03:32<07:50,  1.46s/it]\u001b[A\nEpoch 1 in training:  31%|███▏      | 147/469 [03:34<07:48,  1.46s/it]\u001b[A\nEpoch 1 in training:  32%|███▏      | 148/469 [03:35<07:45,  1.45s/it]\u001b[A\nEpoch 1 in training:  32%|███▏      | 149/469 [03:37<07:47,  1.46s/it]\u001b[A\nEpoch 1 in training:  32%|███▏      | 150/469 [03:38<07:44,  1.46s/it]\u001b[A\nEpoch 1 in training:  32%|███▏      | 151/469 [03:40<07:41,  1.45s/it]\u001b[A\nEpoch 1 in training:  32%|███▏      | 152/469 [03:41<07:39,  1.45s/it]\u001b[A\nEpoch 1 in training:  33%|███▎      | 153/469 [03:43<07:37,  1.45s/it]\u001b[A\ntrain:   0%|          | 0/10 [03:43<?, ?it/s]                         \u001b[A\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_mnist, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m      5\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_mnist, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[9], line 23\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(train_loader, test_loader)\u001b[0m\n\u001b[1;32m     21\u001b[0m x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     22\u001b[0m x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 23\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mmnist_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_hat, y)\n\u001b[1;32m     26\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[7], line 99\u001b[0m, in \u001b[0;36mSineKAN_ViT.forward\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m     96\u001b[0m out \u001b[38;5;241m=\u001b[39m tokens \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embeddings\u001b[38;5;241m.\u001b[39mrepeat(n, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m---> 99\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m out \u001b[38;5;241m=\u001b[39m out[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(out)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[3], line 36\u001b[0m, in \u001b[0;36mNaiveFourierMSA.forward\u001b[0;34m(self, sequence)\u001b[0m\n\u001b[1;32m     33\u001b[0m v_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_mappings[head]\n\u001b[1;32m     35\u001b[0m seq \u001b[38;5;241m=\u001b[39m sequence[:, head\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_head: (head\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_head]\n\u001b[0;32m---> 36\u001b[0m q, k, v \u001b[38;5;241m=\u001b[39m \u001b[43mq_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m, k_map(seq), v_map(seq)\n\u001b[1;32m     38\u001b[0m attention \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(q \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_head \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m))\n\u001b[1;32m     39\u001b[0m seq_res\u001b[38;5;241m.\u001b[39mappend(attention \u001b[38;5;241m@\u001b[39m v)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[2], line 47\u001b[0m, in \u001b[0;36mSineKANLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(x, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dim))\n\u001b[1;32m     46\u001b[0m x_reshaped \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(x, (x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 47\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_reshaped\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mijkl,jkl->ij\u001b[39m\u001b[38;5;124m'\u001b[39m, s, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamplitudes)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_bias:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"path: str = \"sinekan_vit_10epochs.pth\"\n\ntorch.save(mnist_model.state_dict(), path)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T15:07:52.985419Z","iopub.status.idle":"2024-09-01T15:07:52.985787Z","shell.execute_reply.started":"2024-09-01T15:07:52.985610Z","shell.execute_reply":"2024-09-01T15:07:52.985629Z"},"trusted":true},"execution_count":null,"outputs":[]}]}